{{- if eq .Values.daemonset.enabled true -}}
{{- $teams := include "daemonsetTeamConfig" . | fromYaml }}
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: {{ include "nrotel.daemonsetName" . }}
  namespace: {{ .Release.Namespace }}
spec:
  # Mode
  mode: "daemonset"
  managementState: managed

  # Service Account
  serviceAccount: {{ include "nrotel.daemonsetName" . }}

  # Security context for container priviliges
  {{- with .Values.daemonset.securityContext }}
  securityContext: {{ toYaml . | nindent 4 }}
  {{- end }}

  # Annotations for the pods
  podAnnotations:
    prometheus.io/scrape: "false" # This should be false by default. Otherwise 'otelcollector' self scraper job AND 'kubernetes-pods' scrape job will both scrape
  {{- range $key, $val := .Values.daemonset.annotations }}
    {{ $key }}: {{ $val }}
  {{- end }}

  # Ports to expose per service
  ports:
    - name: prometheus
      protocol: TCP
      port: {{ .Values.daemonset.ports.prometheus.port }}
      targetPort: {{ .Values.daemonset.ports.prometheus.targetPort }}

  # Image
  image: "{{ .Values.daemonset.image.repository }}:{{ include "nrotel.daemonsetImageTag" . }}"
  imagePullPolicy: {{ .Values.daemonset.image.pullPolicy }}

  # Resources
  resources:
    requests:
      cpu: {{ .Values.daemonset.resources.requests.cpu }}
      memory: {{ .Values.daemonset.resources.requests.memory }}
    limits:
      cpu: {{ .Values.daemonset.resources.limits.cpu }}
      memory: {{ .Values.daemonset.resources.limits.memory }}

  # Volumes and volume mounts
  volumeMounts:
    - name: varlogpods
      mountPath: /var/log/pods
      readOnly: true
  volumes:
    - name: varlogpods
      hostPath:
        path: /var/log/pods

  tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: NoSchedule
    - key: node-role.kubernetes.io/control-plane
      operator: Exists
      effect: NoSchedule

  # Environment variables
  env:
    - name: MY_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    - name: MY_POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    - name: MY_POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    {{- range $teamName, $teamInfo := $teams }}
      {{- if ne $teamInfo.ignore true }}
    - name: {{ $teamName }}_endpoint
      value: {{ $teamInfo.endpoint }}
        {{- if $teamInfo.licenseKey.secretRef }}
    - name: {{ $teamName }}_licenseKey
      valueFrom:
        secretKeyRef:
          name: {{ $teamInfo.licenseKey.secretRef.name }}
          key: {{ $teamInfo.licenseKey.secretRef.key }}
        {{- else if $teamInfo.licenseKey.value }}
    - name: {{ $teamName }}_licenseKey
      valueFrom:
        secretKeyRef:
          name: {{ include "nrotel.daemonsetName" $ }}-{{ $teamName }}
          key: licenseKey
        {{- end }}
      {{- end }}
    {{- end }}

  # Otel configuration
  config:
    receivers:
      prometheus/self:
        config:
          scrape_configs:
            - job_name: 'otelcollector'
              scrape_interval: {{ .Values.daemonset.prometheus.self.scrapeInterval }}
              static_configs:
              - targets:
                - 127.0.0.1:{{ .Values.daemonset.ports.prometheus.port }}
              {{- if ne (len .Values.daemonset.prometheus.self.importantMetrics) 0 }}
                {{ $metrics := "" -}}
                {{- range $index, $metric := .Values.daemonset.prometheus.self.importantMetrics -}}
                  {{- if eq $index 0 -}}
                    {{- $metrics = printf "%s" $metric -}}
                  {{ else }}
                    {{- $metrics = printf "%s|%s" $metrics $metric -}}
                  {{- end -}}
                {{- end }}
              metric_relabel_configs:
                - source_labels: [__name__]
                  separator: ;
                  regex: {{ $metrics }}
                  replacement: $$1
                  action: keep
              {{- end }}

      {{- with .Values.daemonset.filelog }}
      filelog: {{ toYaml . | nindent 8 }}
      {{- end }}

    processors:
      k8sattributes:
        extract:
          metadata:
          - k8s.namespace.name
          - k8s.deployment.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time

          {{- with .Values.daemonset.processors.k8sattributes.labels }}
          labels: {{ toYaml . | nindent 12 }}
          {{- end }}

          {{- with .Values.daemonset.processors.k8sattributes.annotations }}
          annotations: {{ toYaml . | nindent 12 }}
          {{- end }}

        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection

      attributes:
        actions:
          - key: k8s.cluster.name
            value: {{ .Values.clusterName }}
            action: upsert

      attributes/self:
        actions:
          - key: otelcollector.type
            value: daemonset
            action: upsert
          - key: k8s.node.name
            value: $MY_NODE_NAME
            action: upsert
          - key: k8s.namespace.name
            value: $MY_NAMESPACE_NAME
            action: upsert
          - key: k8s.pod.name
            value: $MY_POD_NAME
            action: upsert

      {{- range $teamName, $teamInfo := $teams }}
        {{- if and (ne $teamInfo.ignore true) (ne (len $teamInfo.namespaces) 0) }}
      filter/{{ $teamName }}:
        error_mode: ignore
        logs:
          log_record:
            - {{ $teamInfo.filter }}
        {{- end }}
      {{- end }}

      memory_limiter:
         check_interval: 1s
         limit_percentage: 80
         spike_limit_percentage: 25

      batch:
        send_batch_max_size: 1000
        timeout: 30s
        send_batch_size : 800

    exporters:
    
      {{- range $teamName, $teamInfo := $teams }}
        {{- if ne $teamInfo.ignore true }}
      otlphttp/{{ $teamName }}:
        endpoint: ${{ $teamName }}_endpoint
        tls:
          insecure: false
        headers:
          api-key: ${{ $teamName }}_licenseKey
        {{- end }}
      {{- end }}

      logging:
        verbosity: detailed

    extensions:
      memory_ballast:
        size_in_percentage: {{ .Values.daemonset.extensions.memory_ballast.size_in_percentage }}

    service:
      extensions:
        - memory_ballast

      pipelines:
        metrics/self:
          receivers:
            - prometheus/self
          processors:
            - memory_limiter
            - k8sattributes
            - attributes
            - attributes/self
            - batch
          exporters:
            - otlphttp/opsteam
            # - logging

        {{- range $teamName, $teamInfo := $teams }}
          {{- if ne $teamInfo.ignore true }}
        logs/{{ $teamName }}:
          receivers:
            - filelog
          processors:
            - memory_limiter
            - k8sattributes
            - attributes
          {{- if ne (len $teamInfo.namespaces) 0 }}
            - filter/{{ $teamName }}
          {{- end }}
            - batch
          exporters:
            - otlphttp/{{ $teamName }}
            # - logging
          {{- end }}
        {{- end }}

      telemetry:
        # logs:
        #   level: DEBUG
        metrics:
          address: 127.0.0.1:{{ .Values.daemonset.ports.prometheus.targetPort }}
{{- end -}}
